{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2pZ5Ios9YtmN"
   },
   "source": [
    "# BERT text classification on movie dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMKBrvUkoFWS"
   },
   "source": [
    "In this notebook, we will use Hugging face [Transformers](https://huggingface.co/transformers/) to build BERT model on text classification task with [Tensorflow 2.0](https://www.tensorflow.org/guide/effective_tf2). \n",
    "\n",
    "Notes: this notebook is entirely run on [Google colab](https://colab.research.google.com/) with GPU. If you start a new notebook, you need to choose \"Runtime\"->\"Change runtime type\" ->\"GPU\" at the begining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J34ii2FxZDR4"
   },
   "source": [
    "### Introduction of BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWqjcn0GXCGW"
   },
   "source": [
    "[BERT](https://https://arxiv.org/abs/1810.04805)  ( which stands for Bidirectional Encoder Representations from\n",
    "Transformers) as a languge model was introduced by Jacob et. al. at 2018 from Google. BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. \n",
    "\n",
    "The core of BERT is tranformer. For those who don't know what is transoformer, [\"Attention Is All You Need\"](https://arxiv.org/abs/1706.03762) and this [blog](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#.Xk1qTChKhPb) are good resources to get an ideal how attention mechanism works and how transformer works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E8glgw8oaXzy"
   },
   "source": [
    "### Introduction of huggingface or Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wUHUS8UaakZ"
   },
   "source": [
    "Hugging face is a company which invented a pacakge called [Transformers](https://github.com/huggingface/transformers). It provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ip5CiZiAqUbz"
   },
   "source": [
    "TensorFlow uses layers of abstraction when putting together a model. Operations (such as matrix algebra) can occur at a low level, and an abstraction of a neural network layer can occur at a higher level. One of these higher levels of abstraction is called a Keras model, and Huggingface uses this model as a way to abstract some of the granular details involved in using BERT for transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHy-9GxObwm-"
   },
   "source": [
    "The Transformer is mainly developed based on the pytorch but the TensorFLow 2.0 version implementation on BERT is also fantasic. I am a fan of tensorflow, so in this notebook, we will implement a classification task using Transformers with TF 2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwIhCLdYbTll"
   },
   "source": [
    "# Run BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UT1t3SBDdaUo"
   },
   "source": [
    "Before we will start taking about the model and data, we need setup packages in Google colab.   \n",
    "So we need to upgrade **pip**, install **tensorflow-gpu 2.0** and **transformers**. It takes about 1 min to run. You may notice here, I use tensorflow-gpu instead of tensorflow, becuase bert use a lot of computation resources, gpu will run much faster than cpu. The good thing is, you only need the gpu package installed. All other operations are same in regular tensorflow. The TF infrastructure will handle it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Cdc5GQ5ZURe"
   },
   "source": [
    "## Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 107913,
     "status": "ok",
     "timestamp": 1582072521038,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "658p25TyYjzI",
    "outputId": "a9d09faa-1be8-46e1-c5f8-05cc05409994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.4MB 15.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 380.8 MB 38 kB/s \n",
      "\u001b[K     |████████████████████████████████| 449 kB 49.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 66.3 MB/s \n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[K     |████████████████████████████████| 475 kB 22.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 56.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 860 kB 104.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 76.9 MB/s \n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q tensorflow-gpu==2.0.0\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4x7p5sIovbw"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMuBbJRpZYB0"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgllRiNSu1LM"
   },
   "source": [
    "In this example , we will use standford movie review sentiment analysis data, it has been upload on [Kaggle](https://www.kaggle.com/atulanandjha/imdb-50k-movie-reviews-test-your-bert). It contian 25000 train and 25000 test review texts and labels as 'pos' and 'neg', which has been anotaited their sentiments. Task is to use text to build claissifier to identify it's sentiment.  I have downloaded it and upload into my repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11613,
     "status": "ok",
     "timestamp": 1582072538821,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "ls0tgkqIZ01M",
    "outputId": "d555b694-1804-4b6f-a1ba-e25ca5e10bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'movie-sst2'...\n",
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 8 (delta 0), reused 8 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (8/8), done.\n",
      "/content/movie-sst2\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yuyongze/movie-sst2.git\n",
    "%cd movie-sst2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sM5nfydUL4O"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Cd0DReyZCPd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.python.lib.io.tf_record import TFRecordWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dv-AKtfz9Uo5"
   },
   "source": [
    "Read csv file, we notice that the sentiment is labeled as 'pos' and 'neg', we replace the 'pos' as 1 and 'neg' as 0,\n",
    "And inthis example, we are using only 20% data (**5000 examples**) as a toy example to demonstrate the model can work well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMu80eJeZ2-D"
   },
   "outputs": [],
   "source": [
    "# fraction of sample pass to the train and test as example\n",
    "SAMPLE_FRAC = 0.2\n",
    "# 80% data for training and 20% data for validate\n",
    "TRAIN_FRAC = 0.8\n",
    "# load train data from train.csv\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "train.reset_index(inplace=True)\n",
    "# change sentiment label form 'pos' and 'neg' to 1 and 0, which bert model knows\n",
    "train['sentiment'].replace({'pos':1,'neg':0},inplace=True)\n",
    "\n",
    "# train set\n",
    "train_sample = train.sample(frac=SAMPLE_FRAC,random_state=0)\n",
    "train_select = train_sample.sample(frac= TRAIN_FRAC,random_state=0)\n",
    "train_csv = train_select.values\n",
    "\n",
    "# validate set \n",
    "validate_select = train_sample.drop(index=train_select.index)\n",
    "validate_csv = validate_select.values\n",
    "\n",
    "\n",
    "# load test data , here should be validation set\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "test.reset_index(inplace=True)\n",
    "test['sentiment'].replace({'pos':1,'neg':0},inplace=True)\n",
    "test_csv = test.sample(frac=SAMPLE_FRAC,random_state=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1483,
     "status": "ok",
     "timestamp": 1582084972079,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "sNS5n-7i4JvL",
    "outputId": "e6db3ebf-699e-41ab-b29e-c2754ca1f8f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>This film is fun, if your a person who likes a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>After seeing this film I feel like I know just...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>first this deserves about 5 stars due to actin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>If you like films that ramble with little plot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>As interesting as a sheet of cardboard, this d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  sentiment\n",
       "24995  24995  This film is fun, if your a person who likes a...          1\n",
       "24996  24996  After seeing this film I feel like I know just...          1\n",
       "24997  24997  first this deserves about 5 stars due to actin...          0\n",
       "24998  24998  If you like films that ramble with little plot...          0\n",
       "24999  24999  As interesting as a sheet of cardboard, this d...          0"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BLdTff0gaEF"
   },
   "source": [
    "As you can see the *train_csv*,*validate_csv*, and *test_csv* has 3 columns, which are 'index','text',and 'sentiment'. They are important, becuase we need to pack those three parts into examples and feed to the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PImmtwWRDSUw"
   },
   "source": [
    "### Build TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d81-HKTNyhLG"
   },
   "source": [
    "We have training data and validate data ready, and now we need convert those data into [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord) which tensorflow can read it into tf.data.Dataset object easily. In this [guide](https://www.tensorflow.org/guide/data), you can find how to transfer data into `tf.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtBjcDJsDRa0"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def create_tf_example(features,label):\n",
    "    \"\"\"\n",
    "    Create tf example using features and label\n",
    "\n",
    "    Args:\n",
    "        features: list, feature list with format  ['idx','sentence']\n",
    "        label: string, \n",
    "\n",
    "    Return:\n",
    "        A binary-string of tf example.\n",
    "        All proto messages can be serialized to a binary-string using the .SerializeToString method.\n",
    "    \"\"\"\n",
    "    tf_example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "        'idx': tf.train.Feature(int64_list=tf.train.Int64List(value=[features[0]])),\n",
    "        'sentence': tf.train.Feature(bytes_list=tf.train.BytesList(value=[features[1].encode('utf-8')])),\n",
    "        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "    }))\n",
    "    return tf_example.SerializeToString()\n",
    "\n",
    "def convert_csv_to_tfrecord(csv, file_name):\n",
    "    \"\"\"\n",
    "    Convert the numpy arryes to tfrecord and write files\n",
    "\n",
    "    Args:\n",
    "        csv: numpy arrays, each row feed (features+label)\n",
    "        file_name: location TFRecord to be saved \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    writer = TFRecordWriter(file_name)\n",
    "    for idx,row in enumerate(csv):\n",
    "        # check the row retionality, raise error when missing value\n",
    "        try:\n",
    "            if row is None:\n",
    "                raise Exception('Row Missing')\n",
    "            if row[0] is None or row[1] is None or row[2] is None:\n",
    "                raise Exception('Value Missing')\n",
    "            if row[1].strip() is '':\n",
    "                raise Exception('Utterance is empty')\n",
    "            \n",
    "            features, label = row[:-1],row[-1]\n",
    "            example =  create_tf_example(features,label)\n",
    "            writer.write(example)\n",
    "\n",
    "        except Exception as inst:\n",
    "            print(type(inst))\n",
    "            print(inst.args)\n",
    "            print(inst)\n",
    "    writer.close()\n",
    "    print(f\"{file_name}: --- {(time.time() - start_time)} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yh5TqvvAJ0_L"
   },
   "source": [
    "convert csv(numpy files) to tfrecord using `convert_csv_to_tfrecord`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3369,
     "status": "ok",
     "timestamp": 1582081386006,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "ep0FZC4wAPvc",
    "outputId": "b8b32563-4785-47e3-8652-ec7046565a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/movie_train.tfrecord: --- 0.16509032249450684 seconds ---\n",
      "data/movie_validate.tfrecord: --- 0.04649686813354492 seconds ---\n",
      "data/movie_test.tfrecord: --- 0.19834470748901367 seconds ---\n"
     ]
    }
   ],
   "source": [
    "convert_csv_to_tfrecord(train_csv, \"./data/movie_train.tfrecord\")\n",
    "convert_csv_to_tfrecord(validate_csv, \"./data/movie_validate.tfrecord\")\n",
    "convert_csv_to_tfrecord(test_csv, \"./data/movie_test.tfrecord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlJkLhfp1Z9b"
   },
   "source": [
    "now we will generate a json file to save number of training example to determine the tranin steps in the later process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8tAYOLt0nHi"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# generate exmaple number , save for use in the future \n",
    "def generate_json_info(local_file_name,df_train=[],df_val=[],df_test=[]):\n",
    "    info = {\"train_length\": len(df_train), \"validation_length\": len(df_val),\n",
    "            \"test_length\": len(df_test)}\n",
    "\n",
    "    with open(local_file_name, 'w') as outfile:\n",
    "        json.dump(info, outfile)\n",
    "\n",
    "generate_json_info('./data/info.json',train_csv,validate_csv,test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W64yQeCyl8sC"
   },
   "source": [
    "#### Confirm that TFRecord has encoded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEQnGaKjkSoW"
   },
   "outputs": [],
   "source": [
    "tr_ds = tf.data.TFRecordDataset(\"data/movie_train.tfrecord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77jQ1Oj5vIgn"
   },
   "source": [
    "About how to write and read tensorflow TFRecord, you can read documentation [here](https://www.tensorflow.org/tutorials/load_data/tfrecord)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jG13LEggmC94"
   },
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_spec = {\n",
    "    'idx': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'sentence': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "def parse_example(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_spec)\n",
    "tr_parse_ds = tr_ds.map(parse_example)\n",
    "dataset_iterator = iter(tr_parse_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1582081388409,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "SUGB587lmxOG",
    "outputId": "48817fe0-849b-4617-b6ed-202d15f1e2cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': <tf.Tensor: id=259301, shape=(), dtype=int64, numpy=8383>,\n",
       " 'label': <tf.Tensor: id=259302, shape=(), dtype=int64, numpy=1>,\n",
       " 'sentence': <tf.Tensor: id=259303, shape=(), dtype=string, numpy=b\"This movie is difficult to watch in our fast-paced culture of the 21st century, but it is worth it for the messages that it conveys, chiefly the consequences and ramifications of technology upon society, specifically when that technology is used for warfare.<br /><br />This movie presents a full circle cycle of dehumanization and rehumanization as influenced by the advent of technology and the subsequent deconstruction of civilization and therefore serves as a cautionary tale against the misuse of technology, but as the circle completes itself, familiar themes and sentiments pop up again to present self-serving rather than self-destructive ways that humanity may utilize technology.<br /><br />Brilliant for it's time, the picture and sound quality may pose a challenge for some, but as a landmark in the history, development, and evolution of the sci-fi genre, it is a must. In the end, free will and free choice are once again posed to humanity as a means for controlling our own destiny rather than having it served to us by someone else or indeed, the state of<br /><br />society itself, as shaped by world events.<br /><br />Those who are downtrodden by what life throws their way sometimes tend to remain so, but yet there is always a glimmer of hope and continuity that remains, as this film posits.<br /><br />As far as qualifying as sci-fi, one of the biggest common demoninators of that genre is it's speculative nature. It asks us the questions, what if these events happened this way, and what effect would it have on society or the individuals within it? How would we react?<br /><br />As far as influence, this film projects those speculative sciences that make sci-fi as unique as it is and keeps us asking those important questions.\">}"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nr2PHpPpnTFV"
   },
   "source": [
    "## BERT Sentiment Classification in TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M71sTxJnnYUF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, glue_convert_examples_to_features\n",
    "from transformers.configuration_bert import BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQVfQl89jA_o"
   },
   "source": [
    "Load the TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_ECdyjqneLw"
   },
   "outputs": [],
   "source": [
    "tr_ds = tf.data.TFRecordDataset(\"data/movie_train.tfrecord\")\n",
    "val_ds = tf.data.TFRecordDataset(\"data/movie_validate.tfrecord\")\n",
    "test_ds = tf.data.TFRecordDataset(\"data/movie_test.tfrecord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hl7slqMfni1r"
   },
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_spec = {\n",
    "    'idx': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'sentence': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "def parse_example(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "# convert the encoded string tensor into the separate tensors that will feed into the model\n",
    "tr_parse_ds = tr_ds.map(parse_example)\n",
    "val_parse_ds = val_ds.map(parse_example)\n",
    "test_parse_ds =  test_ds.map(parse_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PByHYyEqoXJ0"
   },
   "source": [
    "One approach to cleaning up a pipeline is to map a function to the dataset. In this way, the function gets applied to each example. The following code uses this approach to clean up the sentence tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cecBCBXunptj"
   },
   "outputs": [],
   "source": [
    "def clean_string(features):\n",
    "    revised_sentence = tf.strings.regex_replace(features['sentence'], \"\\.\\.\\.\", \"\", replace_global=True)\n",
    "    revised_sentence = tf.strings.regex_replace(revised_sentence, \"\\\\'\", \"'\", replace_global=True)\n",
    "    revised_sentence = tf.strings.regex_replace(revised_sentence, \"\\\\n\", \"\", replace_global=True)\n",
    "    features['sentence'] = revised_sentence\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFuEjr4VobfT"
   },
   "outputs": [],
   "source": [
    "tr_clean_ds = tr_parse_ds.map(lambda features: clean_string(features))\n",
    "val_clean_ds = val_parse_ds.map(lambda features: clean_string(features))\n",
    "test_clean_ds =  test_parse_ds.map(lambda features: clean_string(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbb2UKGhpGoB"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4sRpUggj8om"
   },
   "source": [
    "Before training, we need to set up some paramerter ahead. `BATCH_SIZE`=8 here, it is because in google colab, it will run into a memory issue with bert model at max_length = 512. Usually, the batch_size can be set as 32. USE_XLA and USE_AMP are two methods to help the train speed, in this notebook, we will not discuss that. Therefore, we set them to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRSJMRvCo19j"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "EVAL_BATCH_SIZE = BATCH_SIZE * 2\n",
    "\n",
    "# XLA is the optimizing compiler for machine learning\n",
    "# It can potentially increase speed by 15% with no source code changes\n",
    "USE_XLA = False\n",
    "\n",
    "# mixed precision results on https://github.com/huggingface/transformers/tree/master/examples\n",
    "# Mixed precision can help to speed up training time\n",
    "USE_AMP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AA1mXiWvpSyC"
   },
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(USE_XLA)\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": USE_AMP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1407,
     "status": "ok",
     "timestamp": 1582084078346,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "evLpW1v3pIAI",
    "outputId": "b8de9de2-ad68-4d84-a44f-037c96d05d43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1000, 5000)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steps is determined by the number of examples\n",
    "import json\n",
    "with open('data/info.json') as json_file:\n",
    "    data_info = json.load(json_file)\n",
    "    \n",
    "train_examples = data_info['train_length']\n",
    "valid_examples = data_info['validation_length']\n",
    "test_examples = data_info['test_length']\n",
    "\n",
    "train_examples, valid_examples, test_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ag-jgl6fpd5R"
   },
   "source": [
    "Now that we have a pipeline setup, we need to start the process of converting words into numbers so that they can be processed by the BERT transfer learning backbone. This process is commonly called Tokenization, and Huggingface includes a tokenizer that helps with this process.\n",
    "\n",
    "The tokenizers are based on the underlying research code. For example, the following are different BERT models that can be utilized within the BERT framework:\n",
    "\n",
    "* ``bert-base-uncased``: 12-layer, 768-hidden, 12-heads, 110M parameters\n",
    "* ``bert-large-uncased``: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
    "* ``bert-base-cased``: 12-layer, 768-hidden, 12-heads , 110M parameters\n",
    "* ``bert-large-cased``: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
    "\n",
    "As seen above, the different numbers have different levels of complexity and are associated either with uncapitalized text (uncased) or text that has capitalization. I selected the bert-base-cased underlying model because the movie text have capitalization. I also selected it because in general models that are less complex tend to run faster than models which are more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "baQ8k0-hpxsD"
   },
   "source": [
    "The Transformers framework can use a configuration dictionary in order to set up the hyperparameters for the model. In this case, I explictly use the config to make sure that the model is looking at num_labels=2. If we had been going through an example with three categories ('Positive', 'Negative', and 'Neutral') as opposed to just two cases ('Positive' and 'Negative') then we would have wanted to use num_labels=3 instead. [Ref](https://github.com/huggingface/transformers/blob/master/examples/run_tf_glue.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MD9DEQW5p66N"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer and model from pretrained model/vocabulary. Specify the number of labels to classify (2+: classification, 1: regression)\n",
    "num_labels = 2 \n",
    "config = BertConfig.from_pretrained(\"bert-base-cased\", num_labels=num_labels)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "km300QbipoNu"
   },
   "outputs": [],
   "source": [
    "# Make use of the following config parameters\n",
    "\n",
    "# {\n",
    "#   \"architectures\": [\n",
    "#     \"BertForMaskedLM\"\n",
    "#   ],\n",
    "#   \"attention_probs_dropout_prob\": 0.1,\n",
    "#   \"hidden_act\": \"gelu\",\n",
    "#   \"hidden_dropout_prob\": 0.1,\n",
    "#   \"hidden_size\": 768,\n",
    "#   \"initializer_range\": 0.02,\n",
    "#   \"intermediate_size\": 3072,\n",
    "#   \"max_position_embeddings\": 512,\n",
    "#   \"num_attention_heads\": 12,\n",
    "#   \"num_hidden_layers\": 12,\n",
    "#   \"type_vocab_size\": 2,\n",
    "#   \"vocab_size\": 28996\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "my72gMKaqkMG"
   },
   "source": [
    "Now that we have a tokenizer and the model with the right configurations, we need to take our parsed tensors (the tr_parse_ds or train parsed dataset) and feed them into the Huggingface framework. To do this, we are going to make a slight modification to the glue_convert_examples_to_features code found in the HuggingFace transformers repo. Here we are going to use the sst-2 task (the Stanford Sentiment Treebank binary classification task) because this task also works with binary classification. \n",
    "\n",
    "Notes:\n",
    "\n",
    "Huggingface uses the similar strategy of taking the TFExamples and using a dataset in order to convert the \"sentence\" and \"labels\" into inputs that are needed by BERT (inputs such as 'input_ids', 'attention_mask', and 'token_type_ids'). As disscussed earlier in the workbook, this transformation process makes it quick to test out the conversion on a couple of data points and to move onto the next step without waiting for the full conversion to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16404,
     "status": "ok",
     "timestamp": 1582085683987,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "Sjf-yVZhqd1r",
    "outputId": "64f19ad6-d89f-43c3-8388-96c3487ac853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---14.97620701789856 seconds---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "train_dataset = glue_convert_examples_to_features(examples=tr_clean_ds, tokenizer=tokenizer\n",
    "                                                  , max_length=512, task='sst-2',\n",
    "                                                  label_list=['0','1']\n",
    "                                                  )\n",
    "print(f\"---{time.time()-start_time} seconds---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18330,
     "status": "ok",
     "timestamp": 1582085687704,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "dCNwQ8DLrGqZ",
    "outputId": "f21048aa-53eb-40b9-e65f-e2ef2f143b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---3.7171196937561035 seconds---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "valid_dataset = glue_convert_examples_to_features(examples=val_clean_ds, tokenizer=tokenizer\n",
    "                                                  , max_length=512, task='sst-2'\n",
    "                                                  , label_list =['0', '1'])\n",
    "print(f\"---{time.time()-start_time} seconds---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G7xLA-1rIah"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(train_examples).batch(BATCH_SIZE).repeat(-1)\n",
    "\n",
    "valid_dataset = valid_dataset.batch(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hn3hje_frru3"
   },
   "source": [
    "In this next section, we need to configure the loss function, the optimizer, and any additional metrics that we want to capture.\n",
    "\n",
    "Loss:\n",
    "\n",
    "This is the objective that the model is trying to minimize. In our example, the HuggingFace framework compares this against the distribution of predicted classes. Said differently, we are trying to compare how similar the actual distribution is to the predicted distribution, and this is captured in the loss function called SparseCategoricalCrossentropy .\n",
    "\n",
    "A good discussion on cross entropy can be found at The Gradient\n",
    "\n",
    "Optimizer:\n",
    "\n",
    "Deep learning is the process of minimizing a loss function. The process that determines what steps to try out in each iteration is commonly referred to as the optimizer. For this exercise, I used the Adam optimization algorithm which tends to work well in a variety of situations.\n",
    "\n",
    "Metric:\n",
    "\n",
    "As a basic metric, we should look at the number of times that the actual class is identical to what is predicted.\n",
    "\n",
    "Unfortunately ,the model currently generates unscaled outputs for each example (an unscaled output for the negative class and another unscaled output for the positive class). Said differently, the model generates outputs before they are converted into probabilities (the conversion happens with a softmax function). Because of all of this, the appropriate metric to use would be SparseCategoricalAccuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzQc45bHrevB"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "\n",
    "if USE_AMP:\n",
    "    # loss scaling is currently required when using mixed precision\n",
    "    opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, 'dynamic')\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDGeR6JlsReW"
   },
   "source": [
    "The TensorFlow documentation states the following:\n",
    "\n",
    "**If x is a tf.data dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted.**\n",
    "\n",
    "Because these datasets can be a precursor to training on TFRecords of significant size, it is best practice to specificially state the number of steps that will be processed per epoch in the train and validation stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wp8Hi-QsM4o"
   },
   "outputs": [],
   "source": [
    "train_steps = train_examples//BATCH_SIZE\n",
    "valid_steps = valid_examples//EVAL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cu08x8cJsnnC"
   },
   "source": [
    "GPUs run up to 27x faster that CPUs for model training. Because of this, it is critical that the following preconditions are in place:\n",
    "\n",
    "You are using the version of Tensflow for GPUs\n",
    "The code has access to a GPU\n",
    "To confirm the preconditions, I run the following code to detect GPUs and to see the physical devices that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1582085831303,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "j0VMK32ish7u",
    "outputId": "96f1ca83-b179-4c40-c238-5e07ced5f611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU USAGE\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1790,
     "status": "ok",
     "timestamp": 1582085833726,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "Iq8Vk5lksw3S",
    "outputId": "7e43e621-5286-4ade-a9e8-a9e00d950520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1651914,
     "status": "ok",
     "timestamp": 1582087486998,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "sUS-PgMctD1L",
    "outputId": "725b85b4-f37f-4995-8849-c5a44391f576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 500 steps, validate for 62 steps\n",
      "Epoch 1/3\n",
      "500/500 [==============================] - 561s 1s/step - loss: 0.4208 - accuracy: 0.7883 - val_loss: 0.2677 - val_accuracy: 0.8942\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 543s 1s/step - loss: 0.2023 - accuracy: 0.9268 - val_loss: 0.2334 - val_accuracy: 0.9133\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 542s 1s/step - loss: 0.1015 - accuracy: 0.9672 - val_loss: 0.2833 - val_accuracy: 0.9103\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=3, steps_per_epoch=train_steps,\n",
    "                    validation_data=valid_dataset, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHw-bYXqwkJD"
   },
   "source": [
    "Train for 500 steps, validate for 62 steps\n",
    "Epoch 1/3\n",
    "500/500 [==============================] - 561s 1s/step - loss: 0.4208 - accuracy: 0.7883 - val_loss: 0.2677 - val_accuracy: 0.8942\n",
    "Epoch 2/3\n",
    "500/500 [==============================] - 543s 1s/step - loss: 0.2023 - accuracy: 0.9268 - val_loss: 0.2334 - val_accuracy: 0.9133\n",
    "Epoch 3/3\n",
    "500/500 [==============================] - 542s 1s/step - loss: 0.1015 - accuracy: 0.9672 - val_loss: 0.2833 - val_accuracy: 0.9103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSdH8kBZoqOZ"
   },
   "source": [
    "It tooks about 30mins to train 3 epochs on this setting. And we can acctich 0.91 accuracy on mini dev set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94f_n07BxMI7"
   },
   "source": [
    "### Evaluate the results of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1594644,
     "status": "ok",
     "timestamp": 1582087506070,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "-szQ86ZdtSoc",
    "outputId": "fd3cc87d-aadb-47ae-ea54-9c57478e556e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---19.080271005630493 seconds---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "test_dataset = glue_convert_examples_to_features(examples=test_clean_ds, tokenizer=tokenizer\n",
    "                                                  , max_length=512, task='sst-2'\n",
    "                                                  , label_list =['0', '1'])\n",
    "print(f\"---{time.time()-start_time} seconds---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0O5MKxRQxPEX"
   },
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.batch(EVAL_BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1635225,
     "status": "ok",
     "timestamp": 1582087547634,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "1s9TLEE5xuRG",
    "outputId": "bda3d215-3b81-4ad8-8a6f-98a1b40b0e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 42s 667ms/step - loss: 0.2860 - accuracy: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2859640326868329, 0.909]"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BwVWQHrtWFTK"
   },
   "source": [
    "63/63 [==============================] - 42s 667ms/step - loss: 0.2860 - accuracy: 0.9090\n",
    "[0.2859640326868329, 0.909]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6zjMISBpGCl"
   },
   "source": [
    "As you can see, with only using the small sample size, we can acheive 0.909 accurarcy on test set. It was reported 0.935 in orginal BERT paper in this base model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRZWGTOEyYE-"
   },
   "source": [
    "### Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4lIf-Yuydo9"
   },
   "source": [
    "We can also visualize the evaluation in terms of how many true positives, true negatives, false positives, and false negatives occur. This visualization is commonly called a Confusion Matrix.\n",
    "\n",
    "Creation of the confusion matrix involves the following steps:\n",
    "\n",
    "1) Take the unnormalized outputs from the model (the logits) and compress them into probabilities (that by definition are between 0 and 1). The function that converts logits into probabilities is the softmax function.\n",
    "\n",
    "2) Once you have probabilities for each prediction, identify predicted emotion ('Negative' or 'Positive') by selecting the probability with the largest value. This is accomplished with the argmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dF-v3NBZyXOI"
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(model.predict(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqTwsnZbxvns"
   },
   "outputs": [],
   "source": [
    "y_pred_argmax = tf.math.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_r4smPUZymS5"
   },
   "outputs": [],
   "source": [
    "y_true = tf.Variable([], dtype=tf.int64)\n",
    "\n",
    "for features, label in test_dataset.take(-1):\n",
    "    y_true = tf.concat([y_true, label], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98399,
     "status": "ok",
     "timestamp": 1582087646075,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "ovgupnBby3O8",
    "outputId": "0ce0b28f-15a3-4c9b-ec85-3e7ac6d34009"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEmCAYAAAA3CARoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAWVmZqn0/wFS8bHOjn6W5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def visualize_confusion_matrix(y_pred_argmax, y_true):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y_pred_arg: This is an array with values that are 0 or 1\n",
    "    :param y_true: This is an array with values that are 0 or 1\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    cm = tf.math.confusion_matrix(y_true, y_pred_argmax).numpy()\n",
    "    con_mat_df = pd.DataFrame(cm)\n",
    "    \n",
    "    print(classification_report(y_pred_argmax, y_true))\n",
    "\n",
    "    sns.heatmap(con_mat_df, annot=True, fmt='g', cmap=plt.cm.Blues)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "print(classification_report(test_labels, baseline_predicted))\n",
    "visualize_confusion_matrix(y_pred_argmax, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZcUwKTbzFta"
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29481,
     "status": "ok",
     "timestamp": 1582087714514,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "QJYx2i11y82p",
    "outputId": "26aac95b-b226-4c6a-a08f-ac335ab8636c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./202002/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, './202002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-i1j_FX4mBq"
   },
   "source": [
    "## How-to-use-Saved-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4QrVRwn4puF"
   },
   "source": [
    "In the previous tutorial, we looked at building a sentiment classifier for movie reviews. At the end of that exercise we saved our model so that we can reuse it.\n",
    "\n",
    "As seen in the command below, the SavedModel requires attention_mask, input_ids, and token_type_ids as inputs. These are the inputs that are required by the Google BERT model that we are using. Lucky for us, we can use the HuggingFace Transformers class to convert a sentence into the required inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5541,
     "status": "ok",
     "timestamp": 1582081280282,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "1-kOklKTzOlr",
    "outputId": "178a16af-64d6-49af-e091-0a3012fe1390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['attention_mask'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, 128)\n",
      "      name: serving_default_attention_mask:0\n",
      "  inputs['input_ids'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, 128)\n",
      "      name: serving_default_input_ids:0\n",
      "  inputs['token_type_ids'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, 128)\n",
      "      name: serving_default_token_type_ids:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['output_1'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 2)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir ./202002 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEnGm6_B6fte"
   },
   "source": [
    "The following commands are going to load our model and the tokenizer which converts words into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNQCVvSs5_qn"
   },
   "outputs": [],
   "source": [
    "savedmodel = tf.saved_model.load('./202002')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "to68DWyb6Psj"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLWv7WHf6iQq"
   },
   "source": [
    "The next step in this process is to create something that the Transformers library can process. For our example, we are going to create a dictionary with the required tensors, feed that dictionary into a data pipeline, and have the Transformers library generate input based on the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JU4XNtEb6dL_"
   },
   "outputs": [],
   "source": [
    "example = {'idx': tf.constant(1, dtype=tf.int64), 'label': tf.constant(0, dtype=tf.int64) ,\n",
    "           'sentence': tf.constant('This is the best store that I have ever visited', dtype=tf.string)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vHLGExi46qyr"
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensors(example)\n",
    "feature_ds = glue_convert_examples_to_features(ds, tokenizer, max_length=128, task='sst-2')\n",
    "feature_dataset = feature_ds.batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-tbQJgx68jA"
   },
   "source": [
    "Great! Now we have features in the format required by the Google BERT model. The following function is going to convert these features into an actual prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wilS_mw6wPk"
   },
   "outputs": [],
   "source": [
    "def predict_dataset(feature_dataset, savedmodel):\n",
    "    \"\"\"\n",
    "    :param feature_dataset: Contains information needed for BERT\n",
    "    :param savedmodel: This is the model that has been pretrained in a sep process.\n",
    "    :return: JSON output with the predicted classification. \n",
    "    \"\"\"\n",
    "    \n",
    "    json_examples = []\n",
    "    for feature_batch in feature_dataset.take(-1):\n",
    "        feature_example = feature_batch[0]\n",
    "\n",
    "        # The SavedModel is going to generate log probabilities (logits) as to whether the sentence\n",
    "        # is negative (0) or positive (1).\n",
    "        logits = savedmodel.signatures[\"serving_default\"](attention_mask=feature_example['attention_mask'],\n",
    "                            input_ids=feature_example['input_ids'],\n",
    "                            token_type_ids=feature_example['token_type_ids'])['output_1']\n",
    "        print(f\"logits {logits}\")\n",
    "        \n",
    "        # It is more helpful to have the actual probabilities of success. The TensorFlow softmax \n",
    "        # function will convert the logits into probabilities.\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        \n",
    "        # At this point we have probabilities (probs) of whether the sentence is negative or positive. \n",
    "        # These probabilites (by definition) will always sum to 100%.\n",
    "        \n",
    "        # It would be better though if we could just report out which probability is higher. \n",
    "        # This is done with the argmax function.\n",
    "        \n",
    "        prediction = tf.math.argmax(probs, axis=1)\n",
    "\n",
    "        print(f\"probs {probs}\")\n",
    "        print(f\"prediction {prediction}\")\n",
    "\n",
    "        json_example = {\"SENTIMENT_PREDICTION\": str(prediction.numpy()[0])}\n",
    "        json_examples.append(json_example)\n",
    "\n",
    "    return json_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jf9psPp8OwW"
   },
   "outputs": [],
   "source": [
    "negative_example = {'idx': tf.constant(1, dtype=tf.int64), 'label': tf.constant(0, dtype=tf.int64) ,\n",
    "                    'sentence': tf.constant('This store is absolutely horrible and I hate it!!',\n",
    "                                            dtype=tf.string)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24481,
     "status": "ok",
     "timestamp": 1582087728948,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "EI6Gy4yF8U6i",
    "outputId": "7eb552cb-5f8d-4172-cdd8-4d78c9395de9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': <tf.Tensor: id=313431, shape=(), dtype=int64, numpy=1>,\n",
       " 'label': <tf.Tensor: id=313432, shape=(), dtype=int64, numpy=0>,\n",
       " 'sentence': <tf.Tensor: id=313433, shape=(), dtype=string, numpy=b'This store is absolutely horrible and I hate it!!'>}"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJvS3TvH8WQk"
   },
   "outputs": [],
   "source": [
    "def predict(example, tokenizer, savedmodel):\n",
    "    \"\"\"\n",
    "\n",
    "    :param example: This is a single dictionary of tensors which contains a idx, a label, and a sentence\n",
    "    :return: The prediction in JSON format. 1 is positive, and 0 is negative.\n",
    "    \"\"\"\n",
    "    # The Transformers glue_convert_examples_to_features works well with datasets. \n",
    "    # It does not work well with a dictionary of examples. \n",
    "    ds = tf.data.Dataset.from_tensors(example)\n",
    "    \n",
    "    # Use the transformers library in order to convert an English sentence into something that \n",
    "    # BERT recognizes.\n",
    "    \n",
    "    # The conversion requires giving a label (even if we don't have one). The e-asiest way to get around this is to get around\n",
    "    # this is to assign a default label of zero when you don't have a label. \n",
    "    \n",
    "    feature_ds = glue_convert_examples_to_features(ds, tokenizer, max_length=512, task='sst-2')\n",
    "\n",
    "    feature_dataset = feature_ds.batch(64)\n",
    "    json_examples = predict_dataset(feature_dataset, savedmodel)\n",
    "\n",
    "    return json_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHbQ7vYvWYzP"
   },
   "outputs": [],
   "source": [
    "json_result = predict(negative_example, tokenizer, savedmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joCypzEw8mSr"
   },
   "outputs": [],
   "source": [
    "predict(example, tokenizer, savedmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKTBvk-IVP6e"
   },
   "source": [
    "# Base Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tCZGQu5qQE1"
   },
   "source": [
    "You may wonder how does a baseline model perform on this dataset. Below are only couple lines code using BOW(bag of words) and Logistic Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEkIleF-VPDG"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmTf2JqGVjld"
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = [row[1] for row in train_csv], [row[2] for row in train_csv]\n",
    "test_texts, test_labels =  [row[1] for row in test_csv], [row[2] for row in test_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1582084992328,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "2RcRjmWwXxYT",
    "outputId": "c6cda9e1-fbdc-414e-9f6a-8255e87de521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4000)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts) ,  len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24008,
     "status": "ok",
     "timestamp": 1582085061540,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "6SQ0NpmsVO7J",
    "outputId": "83bf5c52-1e57-4ff7-b2fb-12768b16efff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shrx0pp9VOiq"
   },
   "outputs": [],
   "source": [
    "baseline_predicted = baseline_model.predict(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24715,
     "status": "ok",
     "timestamp": 1582085063921,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "ymHmhkB7YVxE",
    "outputId": "5d215286-3838-46b8-aaf1-ba572c55302c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      2475\n",
      "           1       0.86      0.86      0.86      2525\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, baseline_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1482,
     "status": "ok",
     "timestamp": 1582081129024,
     "user": {
      "displayName": "Yongze Yu",
      "photoUrl": "",
      "userId": "18328208656182681139"
     },
     "user_tz": 300
    },
    "id": "YfikhjchYWcv",
    "outputId": "8fde2760-08d0-4478-b4f0-5f0c105e9bf4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEmCAYAAAA3CARoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npf8PTWe4O0dC/DYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_confusion_matrix(baseline_predicted,test_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPtWNSi5wHW/a2wQOsC2Wgs",
   "collapsed_sections": [],
   "name": "BERT-text-classification-movie.ipynb",
   "provenance": [
    {
     "file_id": "1aA_Dox7RkoOMiDh_CM2wLLURyRl-2xyV",
     "timestamp": 1581984474356
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
